{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:37.249361Z",
     "iopub.status.busy": "2024-11-23T08:56:37.248875Z",
     "iopub.status.idle": "2024-11-23T08:56:46.842255Z",
     "shell.execute_reply": "2024-11-23T08:56:46.841223Z",
     "shell.execute_reply.started": "2024-11-23T08:56:37.249294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchgeometry\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.transforms import functional as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n",
    "from torchgeometry.losses import one_hot\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:46.845791Z",
     "iopub.status.busy": "2024-11-23T08:56:46.844975Z",
     "iopub.status.idle": "2024-11-23T08:56:56.459169Z",
     "shell.execute_reply": "2024-11-23T08:56:56.458109Z",
     "shell.execute_reply.started": "2024-11-23T08:56:46.845745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "!pip install wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.461120Z",
     "iopub.status.busy": "2024-11-23T08:56:56.460781Z",
     "iopub.status.idle": "2024-11-23T08:56:56.468220Z",
     "shell.execute_reply": "2024-11-23T08:56:56.467137Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.461086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check compute device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.469695Z",
     "iopub.status.busy": "2024-11-23T08:56:56.469435Z",
     "iopub.status.idle": "2024-11-23T08:56:56.482305Z",
     "shell.execute_reply": "2024-11-23T08:56:56.481303Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.469669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "train_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.486092Z",
     "iopub.status.busy": "2024-11-23T08:56:56.485708Z",
     "iopub.status.idle": "2024-11-23T08:56:56.495727Z",
     "shell.execute_reply": "2024-11-23T08:56:56.494711Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.486050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomGamma:\n",
    "    def __init__(self, gamma_range=(0.7, 1.3), p=0.2):\n",
    "        self.gamma_range = gamma_range\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1).item() < self.p:\n",
    "            gamma = torch.empty(1).uniform_(*self.gamma_range).item()\n",
    "            return T.adjust_gamma(img, gamma, gain=1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.497252Z",
     "iopub.status.busy": "2024-11-23T08:56:56.496964Z",
     "iopub.status.idle": "2024-11-23T08:56:56.507242Z",
     "shell.execute_reply": "2024-11-23T08:56:56.506442Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.497224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        images_list = os.listdir(images_path)\n",
    "        masks_list = os.listdir(masks_path)\n",
    "        \n",
    "        images_list = [images_path + image_name for image_name in images_list]\n",
    "        self.images_list = images_list\n",
    "        masks_list = [masks_path + mask_name for mask_name in masks_list]\n",
    "        self.masks_list = masks_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        mask_path = self.masks_list[index]\n",
    "        \n",
    "        # Open image and mask\n",
    "        data = Image.open(img_path)\n",
    "        label = Image.open(mask_path)\n",
    "\n",
    "        # Apply transformations\n",
    "        data = self.transform(data)\n",
    "        label = self.transform(label)\n",
    "        \n",
    "        # Normalize the data (if not already done in the transform)\n",
    "        data = data / 255.0  # Normalize image to [0, 1] range if transform doesn't handle it\n",
    "        \n",
    "        # Threshold label to binary mask (or multi-class if needed)\n",
    "        label = torch.where(label > 0.65, 1.0, 0.0)  # Apply thresholding\n",
    "        \n",
    "        # Set the third channel to a small value if you need to manipulate it specifically\n",
    "        if label.shape[0] > 2:  # Check if the label has more than 2 channels\n",
    "            label[2, :, :] = 0.0001\n",
    "            \n",
    "        # Convert the label to class indices (if label is one-hot encoded)\n",
    "        label = torch.argmax(label, dim=0).type(torch.int64)  # Get class indices\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.508969Z",
     "iopub.status.busy": "2024-11-23T08:56:56.508624Z",
     "iopub.status.idle": "2024-11-23T08:56:56.528505Z",
     "shell.execute_reply": "2024-11-23T08:56:56.527446Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.508929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                RandomGamma(gamma_range=(0.7, 1.3), p=0.2),\n",
    "                                transforms.ToTensor()])\n",
    "dataset = CustomDataset('/kaggle/input/bkai-igh-neopolyp/train/train/', '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/', transforms)\n",
    "train_dataset, val_dataset = random_split(dataset, \n",
    "                                    [int(train_split * len(dataset)) , \n",
    "                                     len(dataset) - int(train_split * len(dataset))])\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:56:56.530065Z",
     "iopub.status.busy": "2024-11-23T08:56:56.529729Z",
     "iopub.status.idle": "2024-11-23T08:57:07.027370Z",
     "shell.execute_reply": "2024-11-23T08:57:07.025991Z",
     "shell.execute_reply.started": "2024-11-23T08:56:56.530018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b7\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=3\n",
    ")\n",
    "model.to(device)\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:57:07.029177Z",
     "iopub.status.busy": "2024-11-23T08:57:07.028854Z",
     "iopub.status.idle": "2024-11-23T08:57:07.037353Z",
     "shell.execute_reply": "2024-11-23T08:57:07.036164Z",
     "shell.execute_reply.started": "2024-11-23T08:57:07.029142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps: float = 1e-6\n",
    "        self.weights: torch.Tensor = weights\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor):\n",
    "        # cross entropy loss\n",
    "        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n",
    "        \n",
    "        # compute softmax over the classes axis\n",
    "        input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "        # create the labels one hot tensor\n",
    "        target_one_hot = one_hot(target, num_classes=input.shape[1],\n",
    "                                 device=input.device, dtype=input.dtype)\n",
    "\n",
    "        # compute the actual dice score\n",
    "        dims = (2, 3)\n",
    "        intersection = torch.sum(input_soft * target_one_hot, dims)\n",
    "        cardinality = torch.sum(input_soft + target_one_hot, dims)\n",
    "\n",
    "        dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "        \n",
    "        dice_score = torch.sum(dice_score * self.weights, dim=1)\n",
    "        \n",
    "        return torch.mean(1. - dice_score) + celoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:57:07.039052Z",
     "iopub.status.busy": "2024-11-23T08:57:07.038606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\n",
    "criterion = DiceLoss(weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loss_array = []\n",
    "test_loss_array = []\n",
    "best_val_loss = 9999999\n",
    "wandb.login(\n",
    "    key = \"957a50802d92e6812ca0422419a9d2fb3ebdd174\",\n",
    ")\n",
    "wandb.init(\n",
    "    project = \"BKAI_graph\"\n",
    ")\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, masks in train_loader:  # images, masks are (B, C, H, W)\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, masks.long())  # Use updated DiceLoss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, targets) in enumerate(val_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            loss = criterion(outputs, targets.long())\n",
    "            test_loss += loss.item()\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'train_loss':train_loss,\n",
    "            'val_loss': test_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "    train_loss_array.append(train_loss/len(train_loader))\n",
    "    test_loss_array.append(test_loss/len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {test_loss/len(val_loader):.4f}\")\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": train_loss / len(train_loader),\n",
    "        \"Validation Loss\": test_loss / len(val_loader),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, (data, label) in enumerate(val_loader):\n",
    "     img = data\n",
    "     mask = label\n",
    "     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n",
    "arr[0][0].set_title('Image')\n",
    "arr[0][1].set_title('Segmentation')\n",
    "arr[0][2].set_title('Predict')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "     predict = model(img.to(device))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "     arr[i][0].imshow((img*255)[i].cpu().numpy().transpose(1, 2, 0))\n",
    "    \n",
    "     arr[i][1].imshow(F.one_hot(mask[i]).float())\n",
    "    \n",
    "     arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], dim = 0).cpu()).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, images_path, transform):\n",
    "        super(TestDataset, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        images_list = [images_path+i for i in images_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        data = Image.open(img_path)\n",
    "        h = data.size[1]\n",
    "        w = data.size[0]\n",
    "        data = self.transform(data) / 255        \n",
    "        return data, img_path, h, w\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor()])\n",
    "test_dataset = TestDataset(path, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, (data, path, h, w) in enumerate(test_loader):\n",
    "    img = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, arr = plt.subplots(4, 2, figsize=(16, 12))\n",
    "arr[0][0].set_title('Image')\n",
    "arr[0][1].set_title('Predict')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(img.to(device))\n",
    "\n",
    "for i in range(4):\n",
    "    arr[i][0].imshow((img*255)[i].cpu().numpy().transpose(1, 2, 0))\n",
    "    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n",
    "    os.mkdir(\"/kaggle/working/predicted_masks\")\n",
    "for _, (img, path, H, W) in enumerate(test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_mask = model(img.to(device))\n",
    "    for i in range(len(img)):\n",
    "        image_id = path[i].split('/')[-1].split('.')[0]\n",
    "        filename = image_id + \".png\"\n",
    "        mask2img = Resize((H[i].item(), W[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n",
    "        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 0] = 255\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    \n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
